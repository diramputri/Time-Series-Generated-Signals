---
title: "Simulations of Time Series Data"
author: "Andira Putri"
output: pdf_document
---

#### Generating Time Series Data in R

The function `ts()` can convert a numeric vector into a time series object in R. The syntax is `ts(vectorname, start=, end=, frequency=)`, where start/end are the first/last time points, and frequency is the number of observations per unit in time. `frequency=1` means yearly, `frequency=12` means monthly, etc. Let's generate a time series data set here:

```{r}
set.seed(1)
#randomly generate vector of length 72
vector=rnorm(72,0,1)
#generate time series spanning 6 years
#6 years --> 72 months, frequency=12 puts time series in terms of months
series.1=ts(vector,start=c(2009,1),end=c(2014,12),frequency=12)
plot.ts(series.1)
```

We see that the data revolves around the mean 0, and there is no random walk.

#### Lag

Lag causes a delay so that you can study how similar a time series is to itself. I shift the time series 3 units and superimpose the two series on a plot.

```{r}
fit=lag(series.1,3)
plot.ts(fit,col="blue")
lines(series.1,col="red")
library(forecast)
```

#### Autocovariance and Autocorrelation

Autocorrelation functions (`acf`) are useful for measuring the linear predictability of the series at time t ($x_t$) using only the variable ($x_s$). The function is given by:

$p(s,t)=\frac{\gamma(s,t)}{\sqrt{\gamma(s,s)\gamma(t,t)}}$, where $\gamma(s,t)=cov(x_s,x_t)$ and $\gamma(t,t)=cov(x_t,x_t)=var(x_t)$. Thank you Math Stat.

Given measurements $Y_1, Y_2, ..., Y_N$ at time $X_1, X_2, ..., X_N$, the lag k autocorrelation function is defined as

$r_{k} = \frac{\sum_{i=1}^{N-k}(Y_{i} - \bar{Y})(Y_{i+k} - \bar{Y})} {\sum_{i=1}^{N}(Y_{i} - \bar{Y})^{2} }$

To study autocovariance, use the `arima()` function. For the curious ones, ARIMA stands for AutoRegressive Integrated Moving Average. To study autocorrelation, install the `forecast` library and use the `acf()` function.

```{r}
library(forecast)
acf=acf(series.1)
```